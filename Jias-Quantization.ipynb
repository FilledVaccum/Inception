{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2844ef36-6b4e-4e97-97eb-692e4ed647c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T10:24:14.537346Z",
     "iopub.status.busy": "2025-10-03T10:24:14.537087Z",
     "iopub.status.idle": "2025-10-03T10:24:14.556074Z",
     "shell.execute_reply": "2025-10-03T10:24:14.555493Z",
     "shell.execute_reply.started": "2025-10-03T10:24:14.537326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de47efa93ea143388d5c565e32e0a69a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# only for gated models \n",
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc091e49-0b9a-414c-abaa-0e601fde9306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T10:26:37.478038Z",
     "iopub.status.busy": "2025-10-03T10:26:37.477776Z",
     "iopub.status.idle": "2025-10-03T10:26:37.680996Z",
     "shell.execute_reply": "2025-10-03T10:26:37.680299Z",
     "shell.execute_reply.started": "2025-10-03T10:26:37.478014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: /home/sagemaker-user/.conda/envs/inception/bin/python\n",
      "Python prefix: /home/sagemaker-user/.conda/envs/inception\n",
      "Conda environment: base\n",
      "Conda prefix: /opt/conda\n",
      "Pip location: /home/sagemaker-user/.conda/envs/inception/bin/pip\n",
      "Pip version: pip 25.2 from /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages/pip (python 3.9)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python prefix:\", sys.prefix)\n",
    "print(\"Conda environment:\", os.environ.get('CONDA_DEFAULT_ENV'))\n",
    "print(\"Conda prefix:\", os.environ.get('CONDA_PREFIX'))\n",
    "\n",
    "# Check pip location\n",
    "result = subprocess.run(['which', 'pip'], capture_output=True, text=True)\n",
    "print(\"Pip location:\", result.stdout.strip())\n",
    "\n",
    "# Check pip version\n",
    "result = subprocess.run(['pip', '--version'], capture_output=True, text=True)\n",
    "print(\"Pip version:\", result.stdout.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eee89e2e-c9f4-4e3f-9a55-58f767ea4053",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T10:26:33.744879Z",
     "iopub.status.busy": "2025-10-03T10:26:33.744621Z",
     "iopub.status.idle": "2025-10-03T10:26:33.769759Z",
     "shell.execute_reply": "2025-10-03T10:26:33.769051Z",
     "shell.execute_reply.started": "2025-10-03T10:26:33.744858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed pip location: /home/sagemaker-user/.conda/envs/inception/bin/pip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add environment's bin directory to PATH\n",
    "env_bin = os.path.dirname(sys.executable)\n",
    "current_path = os.environ['PATH']\n",
    "if env_bin not in current_path:\n",
    "    os.environ['PATH'] = f\"{env_bin}:{current_path}\"\n",
    "\n",
    "# Verify fix\n",
    "result = subprocess.run(['which', 'pip'], capture_output=True, text=True)\n",
    "print(\"Fixed pip location:\", result.stdout.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "493b94c6-6363-4db4-b0b3-8d6306adf200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T10:26:46.642252Z",
     "iopub.status.busy": "2025-10-03T10:26:46.641980Z",
     "iopub.status.idle": "2025-10-03T10:26:47.811649Z",
     "shell.execute_reply": "2025-10-03T10:26:47.810981Z",
     "shell.execute_reply.started": "2025-10-03T10:26:46.642228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (4.56.2)\n",
      "Requirement already satisfied: accelerate in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: bitsandbytes in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (0.48.1)\n",
      "Requirement already satisfied: torch in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: psutil in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from triton==3.4.0->torch) (80.9.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from triton==3.4.0->torch) (8.7.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from importlib-metadata->triton==3.4.0->torch) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/sagemaker-user/.conda/envs/inception/lib/python3.9/site-packages (from requests->transformers) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers accelerate bitsandbytes torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b81f5993-e655-4111-a54c-33a7356f4b68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T10:27:30.834910Z",
     "iopub.status.busy": "2025-10-03T10:27:30.834644Z",
     "iopub.status.idle": "2025-10-03T10:48:00.508345Z",
     "shell.execute_reply": "2025-10-03T10:48:00.506618Z",
     "shell.execute_reply.started": "2025-10-03T10:27:30.834889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8e0caf39cd448587391946b7e4ad8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/247 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d91a48c0f541639664f5fe2ff1dab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c13a17f5e98407d979e4a3db12864ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/131 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887865b67ae84208a6ac0451abcc8dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.26k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "689e465580e2437da5f315c12ca8a9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_jais.py:   0%|          | 0.00/6.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/inceptionai/jais-13b-chat:\n",
      "- configuration_jais.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac1108ec9f94486b511e23e60d0ca87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_jais.py:   0%|          | 0.00/68.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/inceptionai/jais-13b-chat:\n",
      "- modeling_jais.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "900b1fa863ac4644ab7aa90f1f7cdb5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin.index.json:   0%|          | 0.00/42.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c870b547fc72404d8c87584f74f1f213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "624c7f1547874e41b8278a787e3c681e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00004-of-00006.bin:   0%|          | 0.00/9.75G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef92ee8d5dc74354b32bf7225f56bba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00005-of-00006.bin:   0%|          | 0.00/9.79G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42225448e73457882db93097a99e72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00003-of-00006.bin:   0%|          | 0.00/9.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82530679833b4bcf9ec5730cbbfc8fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00006.bin:   0%|          | 0.00/9.79G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e36f023a3254ecabd6ff1d05583132f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00006-of-00006.bin:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8c3f82a7aa43ec9a2bf86aa98940f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00006.bin:   0%|          | 0.00/9.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011729916af44570a8cbfc8ce9f2786f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57f5c19f0414d478d200e60a3abeec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model memory footprint: 12.69 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# Configure 8-bit quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,  # Threshold for outlier detection\n",
    "    llm_int8_enable_fp32_cpu_offload=True  # Enable CPU offloading if needed\n",
    ")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_path = \"inceptionai/jais-13b-chat\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "print(f\"Model memory footprint: {model.get_memory_footprint() / 1024**3:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "caa618d8-6839-491d-bfd0-7c5aab2bcb1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T11:35:15.981782Z",
     "iopub.status.busy": "2025-10-03T11:35:15.981523Z",
     "iopub.status.idle": "2025-10-03T11:35:27.344347Z",
     "shell.execute_reply": "2025-10-03T11:35:27.343728Z",
     "shell.execute_reply.started": "2025-10-03T11:35:15.981760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: What is artificial intelligence?\n",
      "Output: What is artificial intelligence?\n",
      "\n",
      "Artificial intelligence (AI) is the science of making computers do things that would require intelligence if done by humans. AI is used in many fields including business, entertainment, and science.\n"
     ]
    }
   ],
   "source": [
    "# Determine device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Prepare prompt\n",
    "test_prompt = \"What is artificial intelligence?\"\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\")\n",
    "\n",
    "# **Move inputs to the model's device**\n",
    "input_ids = inputs.input_ids.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=50,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        use_cache=False\n",
    "    )\n",
    "\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"Input:\", test_prompt)\n",
    "print(\"Output:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9147a55b-ba1d-4840-a190-1db5bb670349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-03T11:35:30.645681Z",
     "iopub.status.busy": "2025-10-03T11:35:30.645398Z",
     "iopub.status.idle": "2025-10-03T11:35:37.911562Z",
     "shell.execute_reply": "2025-10-03T11:35:37.910971Z",
     "shell.execute_reply.started": "2025-10-03T11:35:30.645660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm Jais. I'm an AI assistant created by Inception and MBZUAI.\n"
     ]
    }
   ],
   "source": [
    "# JAIS chat prompt\n",
    "prompt = \"\"\"### Instruction: Your name is Swapnil, and you are named after Jebel Jais.\n",
    "\n",
    "### Input: [|Human|] Hello, can you introduce yourself?\n",
    "### Response: [|AI|]\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "input_ids = inputs.input_ids.to(device)  # Move to GPU if available\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=100,\n",
    "        temperature=0.3,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        use_cache=False\n",
    "    )\n",
    "\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response.split(\"### Response: [|AI|]\")[-1].strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb9115a-03a3-4896-bc7d-32d407c321d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (inception)",
   "language": "python",
   "name": "inception"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
